\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[margin=0.5in]{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{natbib}
\allowdisplaybreaks

%% begin.rcode setup, include=FALSE
% library(knitr)
% opts_chunk$set(fig.width = 5,
%                fig.height = 4,
%                warning = FALSE)
%% end.rcode

\begin{document} 
\title{STAT 243: Final Project}
\author{Jonathan Larson, Chenzhi Li, Courtney Schiffman, \& Shamindra Shrotriya}
\date{December 17th, 2015}

\maketitle

\section{Function Design}

We chose to use a functional coding style as opposed to an object-oriented coding style,
and composed our main function \texttt{ars} from the auxiliary functions
that are summarized in Table 1.
Note that we employed a naming convention wherein all auxiliary functions
begin with the prefix \texttt{faux}.
In order to encourage modularity, we distributed these auxiliary functions
among our group. This necessitated an explicit mapping of the output of early
functions to the input of later functions.
Note also that objects that translate to the same ideas in \cite{Gilks:Wild:1992} are named
in a similar way to each other, and also to how those objects are named
in the paper. For example, \texttt{inp\_Dvec} is used consistently
to represent $D$, and \texttt{inp\_xvec} is used consistently to represent
$T_k$.

A pseudocode summary of the overall function \texttt{ars} is included here:
\begin{verbatim}
ars <- function(n, g, D, k = 100) {
  Check for log-concavity
  Get initial points in Tk
  Get h, uk, lk, and sk
  while (length of sample < n) {
    Sample x* from s
    Generate w ~ uniform(0,1)
    Determine which interval x* falls into
    if (w passes squeezing test) {
      Include x* in sample
    } else if (w passes rejection test) {
      Include x* in sample
      if (there are no numerical issues with the derivative) {
        Include x* in Tk
        Recalculate z, u, l, and s
      }
    }
  }
  return(sample)
}
\end{verbatim}

\begin{table}[]
\centering
\caption{Summary of the inputs/ outputs of the auxiliary functions.}
\label{}
\begin{tabular}{ll}
\hline \\
\textbf{Function Name} & \textbf{Summary}                                                                 \\
\hline \\
\texttt{faux\_CheckLogConcavity} & Takes $g$ and $D$ and returns \texttt{TRUE} if $g$ is log-concave.              \\
                                 & We chose to do one global check at the beginning as opposed to multiple         \\
																 & checks throughout                                                                \\
\texttt{faux\_hx}                & Takes $g$ and returns $h$.                                                       \\
\texttt{faux\_findmode}          & Takes $g$ and $D$ and returns the mode of $g$.                                   \\
                                 & Obtaining initial points in $T_k$ on either side of the mode was how we          \\
																 & ensured $h'(x) > 0$ and $h'(x_k) < 0$.                                           \\
\texttt{faux\_InitChoose}        & Takes $g$, $D$, and an initial $k$ and returns $T_k$.                            \\
\texttt{faux\_hPrimex}           & Takes $g$ and $T_k$ and returns $h'(T_k)$.                                       \\
\texttt{faux\_Lkx}               & Takes $g$ and $T_k$ and returns $l_k$.                                           \\
\texttt{faux\_Zj}                & Takes $g$, $T_k$, and $D$ and returns the $z_j$.                                 \\
\texttt{faux\_uInterval}         & Takes the $z_j$ and returns the intervals between the $z_j$.                     \\
\texttt{faux\_Ukx}               & Takes $g$ and $T_k$ and returns $u_k$.                                           \\
\texttt{faux\_Skx}               & Takes $u_k$ and the intervals between the $z_j$ and returns $s_k$.               \\
\texttt{faux\_SampleSkx}         & Takes $u_k$ and the intervals between the $z_j$ and returns a sample from $s_k$. \\
\hline
\end{tabular}
\end{table}

\section{Testing}

We used \texttt{testthat} throughout our work on this project.
We tested our functions as we created them, and in some cases we modeled
test-driven development by writing the tests before the function.
Writing tests for each others' functions was our main method of code review,
although we did engage in further code review as well as utilising pair programming
to systematically discuss and handle tough corner cases.

The tests for our auxiliary functions mainly took these three forms:
\begin{enumerate}
	\item Validity of input. For example, testing that
	\begin{enumerate}
		\item $g$ is an R function;
		\item $D$ is a numeric vector of length $2$; and
		\item $T_k$ is a numeric vector.
	\end{enumerate}
	\item Validity of output of \texttt{R} object types. For example, testing that
	\begin{enumerate}
		\item \texttt{faux\_CheckLogConcavity} outputs a logical vector of length $1$;
		\item \texttt{faux\_hx} outputs an R function; and
		\item \texttt{faux\_Ukx} outputs a list of R functions.
	\end{enumerate}
	\item Validity of output of values. For example, testing that
	\begin{enumerate}
		\item \texttt{faux\_CheckLogConcavity} detects that $g(x) = \phi(x)$
		is log-concave;
		\item \texttt{faux\_hPrimex} returns $h'(x) = - 2$ for $g(x) = 2e^{-2x}$; and
		\item \texttt{faux\_findmode} returns $0$ for $g(x) = \phi(x)$.
	\end{enumerate}
\end{enumerate}
In addition to the tests for each auxiliary function, we also wrote tests
for the overall \texttt{ars} function, checking its output against theory.
This modular testing structure allowed us to easily create an overall testing
function \texttt{test-main.R} which combined all tests into one.
After all was said and done, we tested the package in the BCE. Please see the 
Appendix for how to use the function with end-to-end testing performed on the 
validity of the output (e.g. histograms).

\section{Documentation}

We used \texttt{roxygen2} to facilitate the creation of documentation. 
Essentially it allows us to create the \texttt{CRAN} style reference manual with 
a single command. We maintained the \texttt{roxygen2} style throughout the coding process, 
ensuring that function descriptions, inputs, outputs, and examples were up-to-date.
We followed the R Style Guide for coding and linting practices,
and heavily commented our code to ensure clarity and to facilitate code
review. Please see appendix for the auto-generated reference manual.

\section{Collaboration}

We used Git in order to collaborate on the code itself. We also created a
private Slack group for collaboration and real-time communication.
Slack employs a markdown-based text formatting interface which allows
easy formatting of code and text.
Lastly, we used a Google doc for group documentation, including
meeting minutes, technical notes on the \texttt{ars} function,
and to-do lists.

We all contributed to the writing of functions, tests, and documentation,
with major contributions breaking down as follows:
\begin{enumerate}
	\item Jonathan wrote \texttt{faux\_CheckLogConcavity} and assisted with
	\texttt{faux\_hx}, \texttt{faux\_Lkx}, \texttt{faux\_Ukx}, and
	\texttt{faux\_SampleSkx}.
	\item Chenzhi wrote \texttt{faux\_hx}, \texttt{faux\_hPrimex}, \texttt{faux\_Lkx}    and \texttt{faux\_Zj}, as well as their tests.
	\item Courtney wrote \texttt{faux\_SampleSkx}, \texttt{faux\_Skx}, and
	\texttt{faux\_uInterval}, and helped to create the final \texttt{ars} function.
	\item Shamindra helped design the testing-documentation-coding-git workflow
    which enabled the team to develop with greater efficiency and also assisted 
    in the coding of \texttt{faux\_findmode}, \texttt{faux\_InitChoose}, \texttt{faux\_hPrimex}, 
    \texttt{faux\_Lkx}, \texttt{faux\_Ukx}, and pair programmed with Courtney on some aspects of \texttt{ars.R}.
\end{enumerate}

\newpage

\section{Appendix}

\subsection{Using the \texttt{ars} Function and some Validity Testing}

Below are some test use cases for the \texttt{ars} function with detailed 
comments. Also shown are some standard statistical tests and histograms which
can help determine the validity of the distribution of the sample points
returned from the \texttt{ars} function. This is effectively a demonstration of 
our end-to-end testing methodology.

%% begin.rcode r-chunk1, cache=TRUE, warning=FALSE, eval=TRUE
% install.packages("../ars.tar.gz", repos=NULL, type="source")
% library(ars)
% 
% # We can reference a standard normal density using R's built in 'dnorm' function
% set.seed(0)
% dnorm_N0_1_1000_Rinbult <- ars(n = 1000, g = dnorm, D = c(-Inf,Inf))
% 
% # We can reference a non-standard normal density using R's built in 'dnorm' 
% # function as well e.g a N(5, 3) density
% # This is done using an anonymous function call
% set.seed(0)
% dnorm_N5_3_1000_Rinbult <- ars(n = 1000, g = function(x) dnorm(x = x, mean = 5
%                                                               , sd = 3)
%                               , D = c(-Inf,Inf))
% 
% # We can reference a density using an explicit form for g(x) directly by writing 
% # it as an explicit function of x e.g. a N(0, 1) density can be done as follows
% set.seed(0)
% dnorm_N0_1_1000_exf <- ars(n = 1000
%                             , g = function(x) (1/sqrt(2*pi))*exp(-(x^2)/2)
%                             , D = c(-Inf,Inf))
% 
% # Other densities can also be tested as follows
% # Chi-Squared with 5 degrees of freedom
% set.seed(0)
% dchisq_5_1000_Rinbult <- ars(1000
%                              , g = function(x) dchisq(x, df = 5)
%                              , D = c(0, Inf))
% 
% # Other densities can also be tested as follows
% # Exponential(10)
% set.seed(0)
% dexp_10_1000_exf <- ars(1000
%                         , g = function(x) 10*exp(-10*x)help()
%                         , D=c(0, Inf))
%% end.rcode

For the above densities we can conduct some some standard statistical tests and 
histograms which can help determine the validity of the distribution of the sample 
points returned from the \texttt{ars} function. This is effectively a demonstration of 
our end-to-end testing methodology.

%% begin.rcode r-chunk2, cache=TRUE, warning=FALSE, eval=TRUE
% # jonno/ courtney - could you please add in our standard testing function here
% # It should accept an input vector of samples and output KS-test, histogram, 
% # QQplot etc
% # We can directly reference the sampled vectors from the previous page as 
% # follows e.g. ars_testing_function()
% # Test 1 - The validity of the standard normal density output as per above
% # testing_function(dnorm_N0_1_1000_Rinbult)
% # Test 2 - The validity of the exp(10) density
% # testing_function(dexp_10_1000_exf)
%% end.rcode

\bibliographystyle{plainnat}
\bibliography{refs}

\end{document}
